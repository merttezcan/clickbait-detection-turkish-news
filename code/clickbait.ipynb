{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **STILL IN DEVELOPMENT**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clickbait Detection using Turkish News Dataset\n",
    "\n",
    "## 1. Introduction\n",
    "\n",
    "Clickbait is one of the common practices in news industry. Even though it's beneficial for the websites, since they are able to attract more visitors, it's not beneficial for the readers. Clickbait is a practice of using misleading headlines to attract more visitors to the website. The main goal of this project is to detect clickbait headlines using Turkish news dataset.\n",
    "\n",
    "## 2. Dataset Characterization\n",
    "\n",
    "The dataset is collected from several websites and it contains 20,036 headlines and their labels. The labels are binary, 1 for clickbait and 0 for non-clickbait. The dataset is available on [Kaggle](https://www.kaggle.com/datasets/suleymancan/turkishnewstitle20000clickbaitclassified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start with the code\n",
    "\n",
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mert/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/mert/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataset: (20038, 4)\n",
      "Number of the clickbait and non-clickbait titles:\n",
      "1.0    10030\n",
      "0.0    10006\n",
      "Name: clickbait, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/merttezcan/clickbait-detection-turkish-news/main/code/data/20000_turkish_news_title.csv')\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "\n",
    "print(\"Number of the clickbait and non-clickbait titles:\")\n",
    "print(df.clickbait.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how is our dataset looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>clickbait</th>\n",
       "      <th>site</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hurriyet.com.tr</td>\n",
       "      <td>İhracatta Türkiye'nin yarısını geçti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hurriyet.com.tr</td>\n",
       "      <td>Borsa İstanbul günü düşüşle tamamladı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hurriyet.com.tr</td>\n",
       "      <td>Londra ve Manchester uçuşlarında yolcu rekoru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nayn.co</td>\n",
       "      <td>CHP’li İlgezdi’den partisine ve Kılıçdaroğlu’n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>nayn.co</td>\n",
       "      <td>Vatandaşın derdine ortak olmaya soyunan bir cu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  clickbait             site  \\\n",
       "0  25892        1.0  hurriyet.com.tr   \n",
       "1  25893        1.0  hurriyet.com.tr   \n",
       "2  25894        1.0  hurriyet.com.tr   \n",
       "3      4        0.0          nayn.co   \n",
       "4      5        0.0          nayn.co   \n",
       "\n",
       "                                               title  \n",
       "0               İhracatta Türkiye'nin yarısını geçti  \n",
       "1              Borsa İstanbul günü düşüşle tamamladı  \n",
       "2  Londra ve Manchester uçuşlarında yolcu rekoru ...  \n",
       "3  CHP’li İlgezdi’den partisine ve Kılıçdaroğlu’n...  \n",
       "4  Vatandaşın derdine ortak olmaya soyunan bir cu...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Our dataset contains 4 columns which are \"id\", \"clickbait\", \"site\", and \"title\". The \"id\" column is the unique identifier for each headline. The \"clickbait\" column is the label of the headline. The \"site\" column is the website where the headline is published. The \"title\" column is the headline itself. We only need the \"clickbait\" and \"title\" columns for our project, since \"clickbait\" column is the label and \"title\" column is the text which we want to analyze. And \"id\" and \"site\" information is not meaningful for our project.\n",
    "\n",
    "So, let's drop the other columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clickbait</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>İhracatta Türkiye'nin yarısını geçti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Borsa İstanbul günü düşüşle tamamladı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Londra ve Manchester uçuşlarında yolcu rekoru ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>CHP’li İlgezdi’den partisine ve Kılıçdaroğlu’n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Vatandaşın derdine ortak olmaya soyunan bir cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Kılıçdaroğlu, 8 Mart Dünya Emekçi Kadınlar Gün...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Abdest nasıl alınır? Abdest alırken hangi dual...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Sıla Hanım, Ahmet Bey’in inançlarına saygısızmış!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20036</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Binali Yıldırım: Hiçbir şekilde hakkınızın kay...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20037</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Kadınlarda En Çok Görülen Hastalıklar ve Tedav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20038 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       clickbait                                              title\n",
       "0            1.0               İhracatta Türkiye'nin yarısını geçti\n",
       "1            1.0              Borsa İstanbul günü düşüşle tamamladı\n",
       "2            1.0  Londra ve Manchester uçuşlarında yolcu rekoru ...\n",
       "3            0.0  CHP’li İlgezdi’den partisine ve Kılıçdaroğlu’n...\n",
       "4            0.0  Vatandaşın derdine ortak olmaya soyunan bir cu...\n",
       "...          ...                                                ...\n",
       "20033        1.0  Kılıçdaroğlu, 8 Mart Dünya Emekçi Kadınlar Gün...\n",
       "20034        1.0  Abdest nasıl alınır? Abdest alırken hangi dual...\n",
       "20035        1.0  Sıla Hanım, Ahmet Bey’in inançlarına saygısızmış!\n",
       "20036        1.0  Binali Yıldırım: Hiçbir şekilde hakkınızın kay...\n",
       "20037        1.0  Kadınlarda En Çok Görülen Hastalıklar ve Tedav...\n",
       "\n",
       "[20038 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(df.columns[[0, 2]],axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change the order of the columns, since it's a more common practice to have the label column as the last column. Also we can rename the \"clickbait\" column to \"label\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>İhracatta Türkiye'nin yarısını geçti</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Borsa İstanbul günü düşüşle tamamladı</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Londra ve Manchester uçuşlarında yolcu rekoru ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHP’li İlgezdi’den partisine ve Kılıçdaroğlu’n...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vatandaşın derdine ortak olmaya soyunan bir cu...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>Kılıçdaroğlu, 8 Mart Dünya Emekçi Kadınlar Gün...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>Abdest nasıl alınır? Abdest alırken hangi dual...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>Sıla Hanım, Ahmet Bey’in inançlarına saygısızmış!</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20036</th>\n",
       "      <td>Binali Yıldırım: Hiçbir şekilde hakkınızın kay...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20037</th>\n",
       "      <td>Kadınlarda En Çok Görülen Hastalıklar ve Tedav...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20038 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  label\n",
       "0                   İhracatta Türkiye'nin yarısını geçti    1.0\n",
       "1                  Borsa İstanbul günü düşüşle tamamladı    1.0\n",
       "2      Londra ve Manchester uçuşlarında yolcu rekoru ...    1.0\n",
       "3      CHP’li İlgezdi’den partisine ve Kılıçdaroğlu’n...    0.0\n",
       "4      Vatandaşın derdine ortak olmaya soyunan bir cu...    0.0\n",
       "...                                                  ...    ...\n",
       "20033  Kılıçdaroğlu, 8 Mart Dünya Emekçi Kadınlar Gün...    1.0\n",
       "20034  Abdest nasıl alınır? Abdest alırken hangi dual...    1.0\n",
       "20035  Sıla Hanım, Ahmet Bey’in inançlarına saygısızmış!    1.0\n",
       "20036  Binali Yıldırım: Hiçbir şekilde hakkınızın kay...    1.0\n",
       "20037  Kadınlarda En Çok Görülen Hastalıklar ve Tedav...    1.0\n",
       "\n",
       "[20038 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['title', 'clickbait']]\n",
    "df.rename(columns = {'clickbait':'label'}, inplace = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We probably have some missing values in our dataset. Let's check it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "label    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title    0\n",
       "label    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only have two missing values in our dataset. We can drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Feature Engineering\n",
    "\n",
    "We can try to find some meaningful features from the \"title\" column which is a text. For example, let's extract the exclamations and question marks from the headlines and create a new feature named contains_exclamation and contains_question_mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_exclamation(title):\n",
    "    if \"!\" in title: \n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "\n",
    "def contains_question_mark(title):\n",
    "    if \"?\" in title: \n",
    "        return 1\n",
    "    else: \n",
    "        return 0    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/c41mw2_11wv75fpzc_9mrb640000gn/T/ipykernel_66270/4238705762.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['contains_exclamation']=df['title'].apply(contains_exclamation)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    17291\n",
       "1     2745\n",
       "Name: contains_exclamation, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['contains_exclamation']=df['title'].apply(contains_exclamation)  \n",
    "\n",
    "df.contains_exclamation.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/c41mw2_11wv75fpzc_9mrb640000gn/T/ipykernel_66270/4079941852.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['contains_question_mark']=df['title'].apply(contains_question_mark)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    18537\n",
       "1     1499\n",
       "Name: contains_question_mark, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['contains_question_mark']=df['title'].apply(contains_question_mark) \n",
    "\n",
    "df.contains_question_mark.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 2,745 headlines which contains exclamation mark and 1,499 headlines which contains question mark.\n",
    "\n",
    "Now we should also remove punctuations and non-alphabetic characters from the headlines, to have a clean text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\n', ' ', text)\n",
    "    text = re.sub('  ', ' ', text)\n",
    "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*', '', text)\n",
    "    text = re.sub('\\[.*?\\]', ' ', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('“','',text)\n",
    "    text = re.sub('”','',text)\n",
    "    text = re.sub('’','',text)\n",
    "    text = re.sub('–','',text)\n",
    "    text = re.sub('‘','',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mert/opt/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:5516: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "feature_engineering_clean = lambda x: clean_text(x)\n",
    "df.title = pd.DataFrame(df.title.apply(feature_engineering_clean)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>contains_exclamation</th>\n",
       "      <th>contains_question_mark</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i̇hracatta türkiyenin yarısını geçti</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>borsa i̇stanbul günü düşüşle tamamladı</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>londra ve manchester uçuşlarında yolcu rekoru ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chpli i̇lgezdiden partisine ve kılıçdaroğluna ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vatandaşın derdine ortak olmaya soyunan bir cu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>kılıçdaroğlu 8 mart dünya emekçi kadınlar günü...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>abdest nasıl alınır abdest alırken hangi duala...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>sıla hanım ahmet beyin inançlarına saygısızmış</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20036</th>\n",
       "      <td>binali yıldırım hiçbir şekilde hakkınızın kayb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20037</th>\n",
       "      <td>kadınlarda en çok görülen hastalıklar ve tedav...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20036 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  label  \\\n",
       "0                   i̇hracatta türkiyenin yarısını geçti    1.0   \n",
       "1                 borsa i̇stanbul günü düşüşle tamamladı    1.0   \n",
       "2      londra ve manchester uçuşlarında yolcu rekoru ...    1.0   \n",
       "3      chpli i̇lgezdiden partisine ve kılıçdaroğluna ...    0.0   \n",
       "4      vatandaşın derdine ortak olmaya soyunan bir cu...    0.0   \n",
       "...                                                  ...    ...   \n",
       "20033  kılıçdaroğlu 8 mart dünya emekçi kadınlar günü...    1.0   \n",
       "20034  abdest nasıl alınır abdest alırken hangi duala...    1.0   \n",
       "20035     sıla hanım ahmet beyin inançlarına saygısızmış    1.0   \n",
       "20036  binali yıldırım hiçbir şekilde hakkınızın kayb...    1.0   \n",
       "20037  kadınlarda en çok görülen hastalıklar ve tedav...    1.0   \n",
       "\n",
       "       contains_exclamation  contains_question_mark  \n",
       "0                         0                       0  \n",
       "1                         0                       0  \n",
       "2                         0                       0  \n",
       "3                         0                       0  \n",
       "4                         0                       0  \n",
       "...                     ...                     ...  \n",
       "20033                     0                       0  \n",
       "20034                     0                       1  \n",
       "20035                     1                       0  \n",
       "20036                     0                       0  \n",
       "20037                     0                       0  \n",
       "\n",
       "[20036 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also count the number of words in the headlines as a feature. Let's create a new feature named \"word_count\" and split the headlines into words, then count the number of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xz/c41mw2_11wv75fpzc_9mrb640000gn/T/ipykernel_66270/2195961232.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['word_count'] = df['title'].apply(lambda x: len(x.split()))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>label</th>\n",
       "      <th>contains_exclamation</th>\n",
       "      <th>contains_question_mark</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i̇hracatta türkiyenin yarısını geçti</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>borsa i̇stanbul günü düşüşle tamamladı</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>londra ve manchester uçuşlarında yolcu rekoru ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chpli i̇lgezdiden partisine ve kılıçdaroğluna ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vatandaşın derdine ortak olmaya soyunan bir cu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20033</th>\n",
       "      <td>kılıçdaroğlu 8 mart dünya emekçi kadınlar günü...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20034</th>\n",
       "      <td>abdest nasıl alınır abdest alırken hangi duala...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20035</th>\n",
       "      <td>sıla hanım ahmet beyin inançlarına saygısızmış</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20036</th>\n",
       "      <td>binali yıldırım hiçbir şekilde hakkınızın kayb...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20037</th>\n",
       "      <td>kadınlarda en çok görülen hastalıklar ve tedav...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20036 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  label  \\\n",
       "0                   i̇hracatta türkiyenin yarısını geçti    1.0   \n",
       "1                 borsa i̇stanbul günü düşüşle tamamladı    1.0   \n",
       "2      londra ve manchester uçuşlarında yolcu rekoru ...    1.0   \n",
       "3      chpli i̇lgezdiden partisine ve kılıçdaroğluna ...    0.0   \n",
       "4      vatandaşın derdine ortak olmaya soyunan bir cu...    0.0   \n",
       "...                                                  ...    ...   \n",
       "20033  kılıçdaroğlu 8 mart dünya emekçi kadınlar günü...    1.0   \n",
       "20034  abdest nasıl alınır abdest alırken hangi duala...    1.0   \n",
       "20035     sıla hanım ahmet beyin inançlarına saygısızmış    1.0   \n",
       "20036  binali yıldırım hiçbir şekilde hakkınızın kayb...    1.0   \n",
       "20037  kadınlarda en çok görülen hastalıklar ve tedav...    1.0   \n",
       "\n",
       "       contains_exclamation  contains_question_mark  word_count  \n",
       "0                         0                       0           4  \n",
       "1                         0                       0           5  \n",
       "2                         0                       0           7  \n",
       "3                         0                       0          13  \n",
       "4                         0                       0          11  \n",
       "...                     ...                     ...         ...  \n",
       "20033                     0                       0           9  \n",
       "20034                     0                       1           8  \n",
       "20035                     1                       0           6  \n",
       "20036                     0                       0           8  \n",
       "20037                     0                       0           8  \n",
       "\n",
       "[20036 rows x 5 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['word_count'] = df['title'].apply(lambda x: len(x.split()))\n",
    "\n",
    "df = df[df['word_count'] != 0]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyze the text, we are going to use a library called \"nltk\". It's a natural language processing library. We can use it to tokenize the text, remove stopwords, and stem the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = [word_tokenize(x) for x in text]\n",
    "    return text\n",
    "\n",
    "#df.title = tokenize(df.title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tokenized our headlines. Now we can remove the stopwords from the headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('turkish')\n",
    "#df.title = df['title'].apply(lambda x: [item for item in x if item not in stopwords_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "coming soon..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Building\n",
    "\n",
    "We can start building our machine learning models. We are going to use several different machine learning models and compare their performance. We are going to use the following models:\n",
    "\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- Support Vector Machine\n",
    "- Random Forest\n",
    "- XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    10030\n",
       "0.0    10006\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(columns='label')\n",
    "y = df['label']\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use sklearn feature_extraction library to convert the text into a meaningful representation for the machine learning models. Let's start with the TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words = stopwords_list,ngram_range = (1,2))\n",
    "tfidf_text_train = tfidf.fit_transform(X_train['title'])\n",
    "tfidf_text_test = tfidf.transform(X_test['title'])\n",
    "\n",
    "X_train_ef = X_train.drop(columns='title')\n",
    "X_test_ef = X_test.drop(columns='title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can combine the features we created with the TfidfVectorizer output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = sparse.hstack([X_train_ef, tfidf_text_train]).tocsr()\n",
    "X_test = sparse.hstack([X_test_ef, tfidf_text_test]).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16028, 132311)\n",
      "(4008, 132311)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Logistic Regression\n",
    "\n",
    "Let's start with the Logistic Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.916645869727976\n",
      "Test Accuracy: 0.8667664670658682\n",
      "Confusion Matrix:\n",
      "[[1695  309]\n",
      " [ 225 1779]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.85      0.86      2004\n",
      "         1.0       0.85      0.89      0.87      2004\n",
      "\n",
      "    accuracy                           0.87      4008\n",
      "   macro avg       0.87      0.87      0.87      4008\n",
      "weighted avg       0.87      0.87      0.87      4008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "lr_train_pred = lr_model.predict(X_train)\n",
    "lr_test_pred = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Train Accuracy:\", accuracy_score(y_train, lr_train_pred))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, lr_test_pred))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lr_test_pred))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "\n",
    "print(classification_report(y_test, lr_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a26c338ef7d335d20efedecc3f72e62e7d181a5ebdbe1803079434b137744f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
